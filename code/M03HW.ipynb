{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M03 Homework\n",
    "\n",
    "### Michael Vaden, mtv2eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new notebook for your work.\n",
    "\n",
    "Parse the Frankenstein text to generate TOKENS and VOCAB tables.\n",
    "\n",
    "Create a list of sentences from the TOKENS table and a list of terms from the VOCAB table.\n",
    "\n",
    "Generate ngram type tables and models, going up to the trigram level."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get TOKENS and VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = f\"{data_home}/pg42324.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frankenstein, by Mary W. Shelley\n"
     ]
    }
   ],
   "source": [
    "OHCO = ['chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "\n",
    "LINES = pd.DataFrame(open(text_file, 'r', encoding='utf-8-sig').readlines(), columns=['line_str'])\n",
    "LINES.index.name = 'line_num'\n",
    "LINES.line_str = LINES.line_str.str.replace(r'\\n+', ' ', regex=True).str.strip()\n",
    "\n",
    "title = LINES.loc[0].line_str.replace('The Project Gutenberg EBook of ', '')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 7671\n"
     ]
    }
   ],
   "source": [
    "clip_pats = [\n",
    "    r\"\\*\\*\\*\\s*START OF (?:THE|THIS) PROJECT\",\n",
    "    r\"\\*\\*\\*\\s*END OF (?:THE|THIS) PROJECT\"\n",
    "]\n",
    "\n",
    "pat_a = LINES.line_str.str.match(clip_pats[0])\n",
    "pat_b = LINES.line_str.str.match(clip_pats[1])\n",
    "\n",
    "line_a = LINES.loc[pat_a].index[0] + 1\n",
    "line_b = LINES.loc[pat_b].index[0] - 1\n",
    "print(line_a, line_b)\n",
    "\n",
    "LINES = LINES.loc[line_a : line_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_pat = r'^(?:LETTER|CHAPTER)\\b'\n",
    "\n",
    "chap_lines = LINES.line_str.str.match(chap_pat, case=True) # Returns a truth vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>LETTER I.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>LETTER II.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>LETTER III.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>LETTER IV.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>CHAPTER I.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>CHAPTER II.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>CHAPTER III.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>CHAPTER IV.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>CHAPTER V.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>CHAPTER VI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>CHAPTER VII.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>CHAPTER VIII.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>CHAPTER IX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>CHAPTER X.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>CHAPTER XI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>CHAPTER XII.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>CHAPTER XIII.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>CHAPTER XIV.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>CHAPTER XV.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>CHAPTER XVI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>CHAPTER XVII.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>CHAPTER XVIII.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>CHAPTER XIX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>CHAPTER XX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>CHAPTER XXI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>CHAPTER XXII.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>CHAPTER XXIII.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>CHAPTER XXIV.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                line_str\n",
       "line_num                \n",
       "343            LETTER I.\n",
       "467           LETTER II.\n",
       "594          LETTER III.\n",
       "636           LETTER IV.\n",
       "918           CHAPTER I.\n",
       "1085         CHAPTER II.\n",
       "1299        CHAPTER III.\n",
       "1555         CHAPTER IV.\n",
       "1789          CHAPTER V.\n",
       "2028         CHAPTER VI.\n",
       "2292        CHAPTER VII.\n",
       "2655       CHAPTER VIII.\n",
       "2958         CHAPTER IX.\n",
       "3165          CHAPTER X.\n",
       "3385         CHAPTER XI.\n",
       "3651        CHAPTER XII.\n",
       "3856       CHAPTER XIII.\n",
       "4061        CHAPTER XIV.\n",
       "4245         CHAPTER XV.\n",
       "4552        CHAPTER XVI.\n",
       "4861       CHAPTER XVII.\n",
       "5046      CHAPTER XVIII.\n",
       "5324        CHAPTER XIX.\n",
       "5572         CHAPTER XX.\n",
       "5905        CHAPTER XXI.\n",
       "6274       CHAPTER XXII.\n",
       "6615      CHAPTER XXIII.\n",
       "6867       CHAPTER XXIV."
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LINES.loc[chap_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES.loc[chap_lines, 'chap_num'] = [i+1 for i in range(LINES.loc[chap_lines].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES.chap_num = LINES.chap_num.ffill()\n",
    "\n",
    "LINES = LINES.dropna(subset=['chap_num']) # Remove everything before Chapter 1\n",
    "\n",
    "LINES = LINES.loc[~chap_lines] # Remove chapter heading lines; their work is done\n",
    "LINES.chap_num = LINES.chap_num.astype('int') # Convert chap_num from float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPS = LINES.groupby(OHCO[:1])\\\n",
    "    .line_str.apply(lambda x: '\\n'.join(x))\\\n",
    "    .to_frame('chap_str')\n",
    "\n",
    "CHAPS['chap_str'] = CHAPS.chap_str.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_pat = r'\\n\\n+'\n",
    "# CHAPS['chap_str'].str.split(para_pat, expand=True).head()\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAS['para_str'] = PARAS['para_str'].str.replace(r'\\n', ' ', regex=True)\n",
    "PARAS['para_str'] = PARAS['para_str'].str.strip()\n",
    "PARAS = PARAS[~PARAS['para_str'].str.match(r'^\\s*$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pat = r'[.?!;:]+'\n",
    "SENTS = PARAS['para_str'].str.split(sent_pat, expand=True).stack()\\\n",
    "    .to_frame('sent_str')\n",
    "SENTS.index.names = OHCO[:3]\n",
    "SENTS = SENTS[~SENTS['sent_str'].str.match(r'^\\s*$')] # Remove empty paragraphs\n",
    "SENTS.sent_str = SENTS.sent_str.str.strip() # CRUCIAL TO REMOVE BLANK TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>_To</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>Saville</td>\n",
       "      <td>saville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">86</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>7</th>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>frankenstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mary</td>\n",
       "      <td>mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>W</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>Shelley</td>\n",
       "      <td>shelley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75941 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         token_str      term_str\n",
       "chap_num para_num sent_num token_num                            \n",
       "1        0        0        0                   _To            to\n",
       "                           1                   Mrs           mrs\n",
       "                  1        0               Saville       saville\n",
       "                           1               England       england\n",
       "                  2        0                     _              \n",
       "...                                            ...           ...\n",
       "28       86       0        7          Frankenstein  frankenstein\n",
       "                           8                    by            by\n",
       "                           9                  Mary          mary\n",
       "                           10                    W             w\n",
       "                  1        0               Shelley       shelley\n",
       "\n",
       "[75941 rows x 2 columns]"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pat = r\"[\\s',-]+\"\n",
    "TOKENS = SENTS['sent_str'].str.split(token_pat, expand=True).stack()\\\n",
    "    .to_frame('token_str')\n",
    "TOKENS.index.names = OHCO[:4]\n",
    "\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>2854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>2105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>indecent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <td>pretended</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6975</th>\n",
       "      <td>warmly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6976</th>\n",
       "      <td>hesitate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6977</th>\n",
       "      <td>shelley</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6978 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          term_str     n\n",
       "term_id                 \n",
       "0              the  4200\n",
       "1              and  2976\n",
       "2                i  2854\n",
       "3               of  2650\n",
       "4               to  2105\n",
       "...            ...   ...\n",
       "6973      indecent     1\n",
       "6974     pretended     1\n",
       "6975        warmly     1\n",
       "6976      hesitate     1\n",
       "6977       shelley     1\n",
       "\n",
       "[6978 rows x 2 columns]"
      ]
     },
     "execution_count": 1090,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "VOCAB = TOKENS.term_str.value_counts().to_frame('n').reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'\n",
    "VOCAB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of sentences from the TOKENS table and a list of terms from the VOCAB table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_padded(token, grouper=['sent_num'], term_str='term_str'):\n",
    "    ohco = token.index.names # We preserve these since they get lost in the shuffle\n",
    "    padded = token.groupby(grouper)\\\n",
    "        .apply(lambda x: '<s> ' + ' '.join(x[term_str]) + ' </s>')\\\n",
    "        .apply(lambda x: pd.Series(x.split()))\\\n",
    "        .stack().to_frame('term_str')\n",
    "    #padded.index.names = ohco\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDED = token_to_padded(TOKENS, grouper=OHCO[:3], term_str='term_str')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate ngram type tables and models, going up to the trigram level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 2\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_to_ngrams(padded, grouper=['sent_num'], n=2):\n",
    "    \n",
    "    ohco = padded.index.names\n",
    "    ngrams = padded.groupby(grouper)\\\n",
    "        .apply(lambda x: pd.concat([x.shift(0-i) for i in range(n)], axis=1))\\\n",
    "        .reset_index(drop=True)\n",
    "    ngrams.index = padded.index\n",
    "    ngrams.columns = widx\n",
    "\n",
    "    # ngrams = pd.concat([padded.shift(0-i) for i in range(n)], axis=1)\n",
    "    # ngrams.index.name = 'ngram_num'\n",
    "    # ngrams.columns = widx\n",
    "    # ngrams = ngrams.fillna('<EOF>')\n",
    "    \n",
    "    return ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 1\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]\n",
    "\n",
    "NGRAMS1 = padded_to_ngrams(PADDED, OHCO[:3], ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 2\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]\n",
    "\n",
    "def ngrams_to_models(ngrams):\n",
    "    global widx\n",
    "    n = len(ngrams.columns)\n",
    "    model = [None for i in range(n)]\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            model[i] = ngrams.value_counts('w0').to_frame('n')\n",
    "            model[i]['p'] = model[i].n / model[i].n.sum()\n",
    "            model[i]['i'] = np.log2(1/model[i].p)\n",
    "        else:\n",
    "            model[i] = ngrams.value_counts(widx[:i+1]).to_frame('n')    \n",
    "            model[i]['cp'] = model[i].n / model[i-1].n\n",
    "            model[i]['i'] = np.log2(1/model[i].cp)\n",
    "        model[i] = model[i].sort_index()\n",
    "    return model\n",
    "M = ngrams_to_models(NGRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 3\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]\n",
    "\n",
    "NGRAMS3 = padded_to_ngrams(PADDED, OHCO[:2], ngrams)\n",
    "\n",
    "M3 = ngrams_to_models(NGRAMS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 1\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]\n",
    "\n",
    "NGRAMS1 = padded_to_ngrams(PADDED, OHCO[:3], ngrams)\n",
    "\n",
    "M1 = ngrams_to_models(NGRAMS1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc. Hint: use the df.query() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>3</th>\n",
       "      <th>17</th>\n",
       "      <th>25</th>\n",
       "      <td>miserable</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>8</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>abhorred</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>25</th>\n",
       "      <th>4</th>\n",
       "      <th>23</th>\n",
       "      <td>detestable</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>28</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>hideous</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">28</th>\n",
       "      <th>4</th>\n",
       "      <th>9</th>\n",
       "      <th>5</th>\n",
       "      <td>hellish</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>6</th>\n",
       "      <th>2</th>\n",
       "      <td>gigantic</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       w0       w1\n",
       "chap_num para_num sent_num                        \n",
       "9        3        17       25   miserable  monster\n",
       "14       8        0        1     abhorred  monster\n",
       "19       25       4        23  detestable  monster\n",
       "20       28       0        1      hideous  monster\n",
       "28       4        9        5      hellish  monster\n",
       "         17       6        2     gigantic  monster"
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = ['a', 'an', 'the', 'this', 'that', '<s>']\n",
    "\n",
    "NGRAMS.query(\"w1 == 'monster' & w0 not in @stop_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['miserable', 'abhorred', 'detestable', 'hideous', 'hellish', 'gigantic']\n"
     ]
    }
   ],
   "source": [
    "print(list(NGRAMS.query(\"w1 == 'monster' & w0 not in @stop_words\")['w0']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.List the following sentences in ascending order of bigram perplexity according to the language model generated from the text:\n",
    "\n",
    "The monster is on the ice.\n",
    "\n",
    "Flowers are happy things.\n",
    "\n",
    "I have never seen the aurora borealis.\n",
    "\n",
    "He never knew the love of a family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The monster is on the ice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers are happy things.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have never seen the aurora borealis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He never knew the love of a family.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sent_str\n",
       "sent_num                                        \n",
       "0                     The monster is on the ice.\n",
       "1                      Flowers are happy things.\n",
       "2         I have never seen the aurora borealis.\n",
       "3            He never knew the love of a family."
      ]
     },
     "execution_count": 1101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SENTS = pd.DataFrame({'sent_str': ['The monster is on the ice.', \n",
    "                                        'Flowers are happy things.', \n",
    "                                        'I have never seen the aurora borealis.', \n",
    "                                        'He never knew the love of a family.']})\n",
    "\n",
    "TEST_SENTS.index.name = 'sent_num'\n",
    "TEST_SENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Convert dataframe of sentences to TOKEN with normalized terms\n",
    "K = TEST_SENTS.sent_str.apply(lambda x: pd.Series(x.split())).stack().to_frame('token_str')\n",
    "K['term_str'] = K.token_str.str.replace(r\"[\\W_]+\", \"\", regex=True).str.lower()\n",
    "K.index.names = ['sent_num', 'token_num']\n",
    "TEST_TOKENS = K\n",
    "\n",
    "#TEST_TOKENS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 2\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PADDED = token_to_padded(TEST_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TEST_NGRAMS = padded_to_ngrams(TEST_PADDED, 'sent_num', ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NGRAMS = TEST_NGRAMS.reset_index().rename({'level_1':'token_num'}, axis=1).groupby(['sent_num', 'token_num']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, ngrams, sents):\n",
    "    \n",
    "    global widx\n",
    "    \n",
    "    assert len(model) == len(ngrams.columns)\n",
    "    \n",
    "    n = len(model)\n",
    "    ohco = ngrams.index.names\n",
    "    \n",
    "    R = []\n",
    "    for i in range(n):\n",
    "        T = ngrams.merge(M[i], on=widx[:i+1], how='left')\n",
    "        T.index = ngrams.index\n",
    "        T = T.reset_index().set_index(ohco + widx).i #.to_frame(f\"i{i}\")\n",
    "        \n",
    "        # This how we handle unseen combos\n",
    "        T[T.isna()] = T.max()\n",
    "        R.append(T.to_frame(f\"i{i}\"))\n",
    "                \n",
    "    return pd.concat(R, axis=1)\n",
    "\n",
    "R = test_model(M, TEST_NGRAMS, TEST_SENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(results, test_sents, n=2):\n",
    "    for i in range(n):\n",
    "        test_sents[f\"pp{i}\"] = np.exp2(results.groupby(['sent_num'])[f\"i{i}\"].mean())\n",
    "    return test_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "      <th>pp0</th>\n",
       "      <th>pp1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The monster is on the ice.</td>\n",
       "      <td>116.056265</td>\n",
       "      <td>80.733835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers are happy things.</td>\n",
       "      <td>586.369721</td>\n",
       "      <td>534.302604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have never seen the aurora borealis.</td>\n",
       "      <td>340.789117</td>\n",
       "      <td>138.907338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He never knew the love of a family.</td>\n",
       "      <td>170.793655</td>\n",
       "      <td>137.060591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sent_str         pp0         pp1\n",
       "sent_num                                                                \n",
       "0                     The monster is on the ice.  116.056265   80.733835\n",
       "1                      Flowers are happy things.  586.369721  534.302604\n",
       "2         I have never seen the aurora borealis.  340.789117  138.907338\n",
       "3            He never knew the love of a family.  170.793655  137.060591"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP = compute_perplexity(R, TEST_SENTS)\n",
    "PP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Using the bigram model represented as a matrix, explore the relationship between bigram pairs using the following lists. Hint: use the .unstack() method on the feature n and then use .loc[] to select the first list from the index, and the second list from the columns.\n",
    "- ['he','she'] to select the indices.\n",
    "- ['said','heard'] to select the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">n</th>\n",
       "      <th colspan=\"2\" halign=\"left\">i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w1</th>\n",
       "      <th>said</th>\n",
       "      <th>heard</th>\n",
       "      <th>said</th>\n",
       "      <th>heard</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.857981</td>\n",
       "      <td>6.928370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.409391</td>\n",
       "      <td>6.409391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n               i          \n",
       "w1   said heard      said     heard\n",
       "w0                                 \n",
       "he   21.0   5.0  4.857981  6.928370\n",
       "she   3.0   3.0  6.409391  6.409391"
      ]
     },
     "execution_count": 1111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_df = M[1].unstack()\n",
    "\n",
    "matrix_df.loc[['he', 'she']].loc[:, (['n', 'i'], ['said', 'heard'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Generate 20 sentences using the generate_text() function. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(M, n=250):\n",
    "    \n",
    "    if len(M) < 3:\n",
    "        raise ValueError(\"Must have trigram model generated.\")\n",
    "    \n",
    "    # Start list of words\n",
    "    first_word = M[1].loc['<s>'].sample(weights='cp').index[0]\n",
    "    \n",
    "    words = ['<s>', first_word]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        bg = tuple(words[-2:])\n",
    "\n",
    "        # Try trigram model\n",
    "        try:\n",
    "            next_word = M[2].loc[bg].sample(weights='cp').index[0]\n",
    "\n",
    "        # If not found in model, back off ...\n",
    "        except KeyError as e1:\n",
    "            try:\n",
    "                # Get the last word in the bigram\n",
    "                ug = bg[1]\n",
    "                next_word = M[1].loc[ug].sample(weights='cp').index[0]\n",
    "            \n",
    "            except KeyError as e2:\n",
    "                next_word = M[0].sample(weights='p').index[0]\n",
    "                \n",
    "        words.append(next_word)\n",
    "    \n",
    "    \n",
    "    text = ' '.join(words[2:])\n",
    "    print('\\n\\n'.join([str(i+1) + ' ' + line.replace('<s>','')\\\n",
    "        .strip().upper() for i, line in enumerate(text.split('</s>'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 THE KNOWLEDGE WHICH I ALONE POSSESSED WAS THE PERIOD FIXED FOR THE ENJOYMENT OF PLEASURE\n",
      "\n",
      "2 \n",
      "\n",
      "3 YOU ARE WELL ACQUAINTED WITH HIM AT PRESENT EXISTING IN THE SUCCESS OF MY FATHER IS IN DEATH\n",
      "\n",
      "4 \n",
      "\n",
      "5 THE SOFT AIR JUST RUFFLED THE WATER\n",
      "\n",
      "6 I SAW MY FRIENDS MY WIFE AND MY HEART WHICH WAS TO DISCOVER ANY CLUE BY WHICH I REGARD MYSELF\n",
      "\n",
      "7 I BELIEVED IN HER GUILT\n",
      "\n",
      "8 THIS CHILD WAS THIN AND VERY HAPPY ONLY A FEW DAYS AT LAUSANNE IN THIS JOURNEY HAD BEEN THE CAUSE\n",
      "\n",
      "9 AT LENGTH ARRIVED\n",
      "\n",
      "10 I TROD HEAVEN IN MY OWN MIND BEGAN TO PLAY AND TO BECOME MY FELLOW CREATURES THEN COULD I DO MY DUTY\n",
      "\n",
      "11 SHE SOMETIMES BEGGED JUSTINE TO FORGIVE HER UNKINDNESS BUT MUCH OFTENER ACCUSED HER OF HAVING CAUSED THE BEST MEANS OF MATERIALLY ASSISTING THE PROGRESS OF YOUR MIND TO AN EXPRESSION OF WILDNESS AND EVEN MADNESS\n",
      "\n",
      "12 BUT WHEN DANIEL NUGENT WAS CALLED SISTER OR AGATHA\n",
      "\n",
      "13 THE PATRIARCHAL LIVES OF ALL EXCELLENCE AND ENDEAVOURED TO WELCOME ME\n",
      "\n",
      "14 BESIDES SOME MONTHS IN PRISON\n",
      "\n",
      "15 EVERY WHERE I AM LOST IN CONJECTURE AS TO CREATURES OF AN ENGLISH PHILOSOPHER THE KNOWLEDGE OF LANGUAGE\n",
      "\n",
      "16 A FEW MISERABLE COWS AND OATMEAL FOR ITS HOSPITALITY\n",
      "\n",
      "17 MELANCHOLY FOLLOWED BUT BY DEGREES ONE HERB FROM ANOTHER\n",
      "\n",
      "18 \n",
      "\n",
      "19 THE WOUNDED DEER DRAGGING ITS FAINTING LIMBS TO SOME ONE A FRIEND OF MY LABOURS IN SOME DEGREE ALARMED ME\n",
      "\n",
      "20 I RETIRED TO A HUMAN CREATURE\n"
     ]
    }
   ],
   "source": [
    "generate_text(M3, n = 270)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Compute the redundancy for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the .mle feature... \n",
    "\n",
    "Does R increase, decrease, or remain the same as the choice of n-gram increases in length?\n",
    "\n",
    "N is computed as the number of all possible combinations for each ngram. So, for the bigram model N is the number of unigrams (i.e. the vocabulary size plus the sentence boundary signs) squared, and for the trigram model the value is cubed, i.e.\n",
    "N = len(M[0].index)**{i+1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3[1]['p'] = M3[1].n /  M3[1].n.sum()\n",
    "M3[2]['p'] = M3[2].n /  M3[2].n.sum()\n",
    "\n",
    "M3[0]['h'] = M3[0]['p'] * M3[0]['i']\n",
    "M3[1]['h'] = M3[1]['p'] * M3[1]['i']\n",
    "M3[2]['h'] = M3[2]['p'] * M3[2]['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1 = M3[0]['h'].sum()\n",
    "H2 = M3[1]['h'].sum()\n",
    "H3 = M3[2]['h'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_terms1 = M3[0]['n'].count()\n",
    "n_terms2 = M3[1]['n'].count()\n",
    "n_terms3 = M3[2]['n'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hmax1 = np.log2(n_terms1)\n",
    "Hmax2 = np.log2(n_terms2)\n",
    "Hmax3 = np.log2(n_terms3)\n",
    "\n",
    "R1 = 1 - (H1/Hmax1)\n",
    "R2 = 1 - (H2/Hmax2)\n",
    "R3 = 1 - (H3/Hmax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Redundancy: 0.30885786469975895\n",
      "Bigram Redundancy: 0.6843823899586926\n",
      "Trigram Redundancy: 0.8838055825847118\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unigram Redundancy: {R1}\")\n",
    "print(f\"Bigram Redundancy: {R2}\")\n",
    "print(f\"Trigram Redundancy: {R3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
