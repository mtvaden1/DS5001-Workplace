{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M04 Homework\n",
    "\n",
    "### Michael Vaden, mtv2eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import plotly_express as px\n",
    "from lib.textparser import TextParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = f'{data_home}/eliot-set'\n",
    "data_prefix = 'ELIOT_GEORGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>raw_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE MIDDLEMARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE ADAM BEDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE THE MILL ON THE FLOSS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "145      /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "507      /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "6688     /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "\n",
       "                                  raw_title  \n",
       "book_id                                      \n",
       "145                ELIOT GEORGE MIDDLEMARCH  \n",
       "507                  ELIOT GEORGE ADAM BEDE  \n",
       "6688     ELIOT GEORGE THE MILL ON THE FLOSS  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_list = sorted(glob(f\"{source_files}/*.*\"))\n",
    "\n",
    "#source_file_list\n",
    "book_data = []\n",
    "\n",
    "for source_file_path in source_file_list:\n",
    "    book_id = int(source_file_path.split('-')[-1].split('.')[0].replace('pg',''))\n",
    "    book_title = source_file_path.split('/')[-1].split('-')[0].replace('_', ' ')\n",
    "    book_data.append((book_id, source_file_path, book_title))\n",
    "\n",
    "LIB = pd.DataFrame(book_data, columns=['book_id','source_file_path','raw_title'])\\\n",
    "    .set_index('book_id').sort_index()\n",
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_pats = [\n",
    "    r\"\\*\\*\\*\\s*START OF\",\n",
    "    r\"\\*\\*\\*\\s*END OF\"\n",
    "]\n",
    "\n",
    "# All are 'chap'and 'm'\n",
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "ohco_pat_list = [\n",
    "    (145, rf\"^\\s*CHAPTER\\s+{roman}\\.s*$\"),\n",
    "    (507,   rf\"^\\s*Chapter\\s+{roman}\\s*$\"),\n",
    "    (6688,   rf\"^\\s*Chapter\\s+{roman}\\.s*$\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['chap_regex'] = LIB.index.map(pd.Series({x[0]:x[1] for x in ohco_pat_list}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>raw_title</th>\n",
       "      <th>chap_regex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE MIDDLEMARCH</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\.s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE ADAM BEDE</td>\n",
       "      <td>^\\s*Chapter\\s+[IVXLCM]+\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE THE MILL ON THE FLOSS</td>\n",
       "      <td>^\\s*Chapter\\s+[IVXLCM]+\\.s*$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "145      /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "507      /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "6688     /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "\n",
       "                                  raw_title                    chap_regex  \n",
       "book_id                                                                    \n",
       "145                ELIOT GEORGE MIDDLEMARCH  ^\\s*CHAPTER\\s+[IVXLCM]+\\.s*$  \n",
       "507                  ELIOT GEORGE ADAM BEDE   ^\\s*Chapter\\s+[IVXLCM]+\\s*$  \n",
       "6688     ELIOT GEORGE THE MILL ON THE FLOSS  ^\\s*Chapter\\s+[IVXLCM]+\\.s*$  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_collection(LIB):\n",
    "\n",
    "    clip_pats = [\n",
    "        r\"\\*\\*\\*\\s*START OF\",\n",
    "        r\"\\*\\*\\*\\s*END OF\"\n",
    "    ]\n",
    "\n",
    "    books = []\n",
    "    for book_id in LIB.index:\n",
    "\n",
    "        # Announce\n",
    "        print(\"Tokenizing\", book_id, LIB.loc[book_id].raw_title)\n",
    "\n",
    "        # Define vars\n",
    "        chap_regex = LIB.loc[book_id].chap_regex\n",
    "        ohco_pats = [('chap', chap_regex, 'm')]\n",
    "        src_file_path = LIB.loc[book_id].source_file_path\n",
    "\n",
    "        # Create object\n",
    "        text = TextParser(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats, use_nltk=True)\n",
    "\n",
    "        # Define parameters\n",
    "        text.verbose = True\n",
    "        text.strip_hyphens = True\n",
    "        text.strip_whitespace = True\n",
    "\n",
    "        print(text)\n",
    "\n",
    "        # Parse\n",
    "        text.import_source().parse_tokens()\n",
    "\n",
    "        # Name things\n",
    "        text.TOKENS['book_id'] = book_id\n",
    "        text.TOKENS = text.TOKENS.reset_index().set_index(['book_id'] + text.OHCO)\n",
    "\n",
    "        # Add to list\n",
    "        books.append(text.TOKENS)\n",
    "        \n",
    "    # Combine into a single dataframe\n",
    "    CORPUS = pd.concat(books).sort_index()\n",
    "\n",
    "    # Clean up\n",
    "    del(books)\n",
    "    del(text)\n",
    "        \n",
    "    print(\"Done\")\n",
    "        \n",
    "    return CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing 145 ELIOT GEORGE MIDDLEMARCH\n",
      "<lib.textparser.TextParser object at 0x7fab9790ef70>\n",
      "Importing  /Users/michaelvaden/GithubRepos/DS5001-Workplace/data/eliot-set/ELIOT_GEORGE_MIDDLEMARCH-pg145.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*CHAPTER\\s+[IVXLCM]+\\.s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 507 ELIOT GEORGE ADAM BEDE\n",
      "<lib.textparser.TextParser object at 0x7fab7de78550>\n",
      "Importing  /Users/michaelvaden/GithubRepos/DS5001-Workplace/data/eliot-set/ELIOT_GEORGE_ADAM_BEDE-pg507.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*Chapter\\s+[IVXLCM]+\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 6688 ELIOT GEORGE THE MILL ON THE FLOSS\n",
      "<lib.textparser.TextParser object at 0x7fab6d85e250>\n",
      "Importing  /Users/michaelvaden/GithubRepos/DS5001-Workplace/data/eliot-set/ELIOT_GEORGE_THE_MILL_ON_THE_FLOSS-pg6688.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*Chapter\\s+[IVXLCM]+\\.s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "CORPUS = tokenize_collection(LIB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A library LIB with the following metadata (and data) about each book:\n",
    "The book_id, matching the first level of the index in the CORPUS.\n",
    "The raw book title will be sufficient, i.e. with title and author combined.\n",
    "The path of the source file.\n",
    "The regex used to parse chapter milestones.\n",
    "The length of the book (number of tokens).\n",
    "The number of chapters in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>raw_title</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>book_len</th>\n",
       "      <th>n_chaps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE MIDDLEMARCH</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\.s*$</td>\n",
       "      <td>317305</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE ADAM BEDE</td>\n",
       "      <td>^\\s*Chapter\\s+[IVXLCM]+\\s*$</td>\n",
       "      <td>215404</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>/Users/michaelvaden/GithubRepos/DS5001-Workpla...</td>\n",
       "      <td>ELIOT GEORGE THE MILL ON THE FLOSS</td>\n",
       "      <td>^\\s*Chapter\\s+[IVXLCM]+\\.s*$</td>\n",
       "      <td>207461</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "145      /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "507      /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "6688     /Users/michaelvaden/GithubRepos/DS5001-Workpla...   \n",
       "\n",
       "                                  raw_title                    chap_regex  \\\n",
       "book_id                                                                     \n",
       "145                ELIOT GEORGE MIDDLEMARCH  ^\\s*CHAPTER\\s+[IVXLCM]+\\.s*$   \n",
       "507                  ELIOT GEORGE ADAM BEDE   ^\\s*Chapter\\s+[IVXLCM]+\\s*$   \n",
       "6688     ELIOT GEORGE THE MILL ON THE FLOSS  ^\\s*Chapter\\s+[IVXLCM]+\\.s*$   \n",
       "\n",
       "         book_len  n_chaps  \n",
       "book_id                     \n",
       "145        317305       86  \n",
       "507        215404       55  \n",
       "6688       207461       58  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB['book_len'] = CORPUS.groupby('book_id').term_str.count()\n",
    "\n",
    "LIB['n_chaps'] = CORPUS.reset_index()[['book_id','chap_id']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('book_id').chap_id.count()\n",
    "\n",
    "LIB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An aggregate of all the novels' tokens CORPUS with an appropriate OHCO index, with following features:\n",
    "The token string.\n",
    "The term string.\n",
    "The part-of-speech tag inferred by NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">145</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Since, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>Since</td>\n",
       "      <td>since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(I, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(can, MD)</td>\n",
       "      <td>MD</td>\n",
       "      <td>can</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(do, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>do</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(no, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6688</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">58</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">69</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>2</th>\n",
       "      <td>(death, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>death</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(they, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>they</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(were, VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>were</td>\n",
       "      <td>were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(not, RB)</td>\n",
       "      <td>RB</td>\n",
       "      <td>not</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(divided.”, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>divided.”</td>\n",
       "      <td>divided</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740213 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos  token_str  \\\n",
       "book_id chap_id para_num sent_num token_num                                    \n",
       "145     1       0        0        0              (Since, IN)   IN      Since   \n",
       "                                  1                 (I, PRP)  PRP          I   \n",
       "                                  2                (can, MD)   MD        can   \n",
       "                                  3                 (do, VB)   VB         do   \n",
       "                                  4                 (no, DT)   DT         no   \n",
       "...                                                      ...  ...        ...   \n",
       "6688    58      69       0        2              (death, NN)   NN      death   \n",
       "                                  3              (they, PRP)  PRP       they   \n",
       "                                  4              (were, VBD)  VBD       were   \n",
       "                                  5                (not, RB)   RB        not   \n",
       "                                  6          (divided.”, JJ)   JJ  divided.”   \n",
       "\n",
       "                                            term_str  \n",
       "book_id chap_id para_num sent_num token_num           \n",
       "145     1       0        0        0            since  \n",
       "                                  1                i  \n",
       "                                  2              can  \n",
       "                                  3               do  \n",
       "                                  4               no  \n",
       "...                                              ...  \n",
       "6688    58      69       0        2            death  \n",
       "                                  3             they  \n",
       "                                  4             were  \n",
       "                                  5              not  \n",
       "                                  6          divided  \n",
       "\n",
       "[740213 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vocabulary VOCAB of terms extracted from CORPUS, with the following annotation features derived from either NLTK or by using operations presented in the notebook:\n",
    "Stopwords.\n",
    "Porter stems.\n",
    "Maximum POS; i.e. the most frequently associated POS tag for the term using .idxmax(). Note that ties are handled by the method.\n",
    "POS ambiguity expressed a number of POS tags associated with a term's tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/ny1859490sj527r3gf8tnfrh0000gn/T/ipykernel_90820/2191212758.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CORPUS['pos_group'] = CORPUS.pos.str[:2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>n_pos_group</th>\n",
       "      <th>cat_pos_group</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>cat_pos</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1790</td>\n",
       "      <td>1790</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>18.497458</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1799</td>\n",
       "      <td>1799</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801more</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1801more</td>\n",
       "      <td>1801more</td>\n",
       "      <td>1801more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1</td>\n",
       "      <td>{CD}</td>\n",
       "      <td>1807</td>\n",
       "      <td>1807</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>œdipus</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>18.497458</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>1</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>œdipu</td>\n",
       "      <td>œdipus</td>\n",
       "      <td>œdip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>μέγεθος</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>1</td>\n",
       "      <td>{NNP}</td>\n",
       "      <td>μέγεθος</td>\n",
       "      <td>μέγεθος</td>\n",
       "      <td>μέγεθος</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>τι</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>1</td>\n",
       "      <td>{NNP}</td>\n",
       "      <td>τι</td>\n",
       "      <td>τι</td>\n",
       "      <td>τι</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ἀπέρωτος</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "      <td>{JJ}</td>\n",
       "      <td>1</td>\n",
       "      <td>{JJ}</td>\n",
       "      <td>ἀπέρωτος</td>\n",
       "      <td>ἀπέρωτος</td>\n",
       "      <td>ἀπέρωτος</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ἒρως</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.497458</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>{NN}</td>\n",
       "      <td>1</td>\n",
       "      <td>{NNP}</td>\n",
       "      <td>ἒρως</td>\n",
       "      <td>ἒρως</td>\n",
       "      <td>ἒρως</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26337 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          n  n_chars         p          i max_pos max_pos_group  n_pos_group  \\\n",
       "term_str                                                                       \n",
       "1         1        1  0.000001  19.497458      CD            CD            1   \n",
       "1790      1        4  0.000001  19.497458      CD            CD            1   \n",
       "1799      2        4  0.000003  18.497458      CD            CD            1   \n",
       "1801more  1        8  0.000001  19.497458      CD            CD            1   \n",
       "1807      1        4  0.000001  19.497458      CD            CD            1   \n",
       "...      ..      ...       ...        ...     ...           ...          ...   \n",
       "œdipus    2        6  0.000003  18.497458      NN            NN            1   \n",
       "μέγεθος   1        7  0.000001  19.497458     NNP            NN            1   \n",
       "τι        1        2  0.000001  19.497458     NNP            NN            1   \n",
       "ἀπέρωτος  1        8  0.000001  19.497458      JJ            JJ            1   \n",
       "ἒρως      1        4  0.000001  19.497458     NNP            NN            1   \n",
       "\n",
       "         cat_pos_group  n_pos cat_pos stem_porter stem_snowball stem_lancaster  \n",
       "term_str                                                                        \n",
       "1                 {CD}      1    {CD}           1             1              1  \n",
       "1790              {CD}      1    {CD}        1790          1790           1790  \n",
       "1799              {CD}      1    {CD}        1799          1799           1799  \n",
       "1801more          {CD}      1    {CD}    1801more      1801more       1801more  \n",
       "1807              {CD}      1    {CD}        1807          1807           1807  \n",
       "...                ...    ...     ...         ...           ...            ...  \n",
       "œdipus            {NN}      1    {NN}       œdipu        œdipus           œdip  \n",
       "μέγεθος           {NN}      1   {NNP}     μέγεθος       μέγεθος        μέγεθος  \n",
       "τι                {NN}      1   {NNP}          τι            τι             τι  \n",
       "ἀπέρωτος          {JJ}      1    {JJ}    ἀπέρωτος      ἀπέρωτος       ἀπέρωτος  \n",
       "ἒρως              {NN}      1   {NNP}        ἒρως          ἒρως           ἒρως  \n",
       "\n",
       "[26337 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS = CORPUS[CORPUS.term_str != '']\n",
    "CORPUS['pos_group'] = CORPUS.pos.str[:2]\n",
    "\n",
    "\n",
    "VOCAB = CORPUS.term_str.value_counts().to_frame('n').sort_index()\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)\n",
    "\n",
    "VOCAB['max_pos'] = CORPUS[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "VOCAB['max_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "\n",
    "VOCAB['n_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack().count(1)\n",
    "VOCAB['cat_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().to_frame('n').reset_index()\\\n",
    "    .groupby('term_str').pos_group.apply(lambda x: set(x))\n",
    "VOCAB['n_pos'] = CORPUS[['term_str','pos']].value_counts().unstack().count(1)\n",
    "VOCAB['cat_pos'] = CORPUS[['term_str','pos']].value_counts().to_frame('n').reset_index()\\\n",
    "    .groupby('term_str').pos.apply(lambda x: set(x))\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "VOCAB['stem_snowball'] = VOCAB.apply(lambda x: stemmer2.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "VOCAB['stem_lancaster'] = VOCAB.apply(lambda x: stemmer3.stem(x.name), 1)\n",
    "\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f'{output_dir}/{data_prefix}'\n",
    "LIB.to_csv(f'{out_path}-LIB.csv')\n",
    "VOCAB.to_csv(f'{out_path}-VOCAB.csv')\n",
    "CORPUS.to_csv(f'{out_path}-CORPUS.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have these, use the dataframes to answer these questions:\n",
    "\n",
    "What regular expression did you use to chunk _Middlemarch_ into chapters?\n",
    "\n",
    "What is the title of the book that has the most tokens? \n",
    "\n",
    "How many chapter level chunks are there in this novel?\n",
    "\n",
    "Among the three stemming algorithms -- Porter, Lancaster, and Snowball --  which is the most aggressive, in terms of the number of words associated with each stem?\n",
    "\n",
    "Using the most aggressive stemmer from the previous question, what is the stem with the most associated terms?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.What regular expression did you use to chunk _Middlemarch_ into chapters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id\n",
       "145    ^\\s*CHAPTER\\s+[IVXLCM]+\\.s*$\n",
       "Name: chap_regex, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.query(\"book_id == 145\")['chap_regex']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.What is the title of the book that has the most tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ELIOT GEORGE MIDDLEMARCH'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.sort_values('book_len', ascending=False).iloc[0,:]['raw_title']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.How many chapter level chunks are there in this novel? (Middlemarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.sort_values('book_len', ascending=False).iloc[0,:]['n_chaps']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Among the three stemming algorithms -- Porter, Lancaster, and Snowball --  which is the most aggressive, in terms of the number of words associated with each stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17540 unique stems for Porter\n",
      "There are 14612 unique stems for Lancester\n",
      "There are 17203 unique stems for Snowball\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(VOCAB.stem_porter.unique())} unique stems for Porter\")\n",
    "print(f\"There are {len(VOCAB.stem_lancaster.unique())} unique stems for Lancester\")\n",
    "print(f\"There are {len(VOCAB.stem_snowball.unique())} unique stems for Snowball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.197833523375145"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.reset_index().groupby(['stem_porter'])['n'].sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.024472475730974"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.reset_index().groupby(['stem_snowball'])['n'].sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.653572406241445"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.reset_index().groupby(['stem_lancaster'])['n'].sum().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results above that **Lancester** has the fewest unique stems and the highest average associated words per stem, so we consider it to be the most aggressive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Using the most aggressive stemmer from the previous question, what is the stem with the most associated terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cont    34\n",
       "man     27\n",
       "com     25\n",
       "adv     21\n",
       "pass    19\n",
       "Name: stem_lancaster, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB['stem_lancaster'].value_counts().head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cont** is the stem  with the most (unique) associated terms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
