{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M02 Homework\n",
    "\n",
    "### Michael Vaden, mtv2eva"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will convert a different text from raw text into a data frame of tokens and preserving its OHCO. Then you will extract some statistical features from the resulting corpus.\n",
    "\n",
    "Follow these instructions:\n",
    "\n",
    "Download the attached Gutenberg version of Jane Austen's Sense and Sensibility (pg161.txt Download pg161.txt).\n",
    "\n",
    "Create a notebook  to convert the raw text into a data frame of tokens, just as we did with Persuasion.\n",
    "\n",
    "You may use the notebook from the lab as your guide.\n",
    "\n",
    "Specifically, make sure your complete these tasks:\n",
    "\n",
    "Remove Gutenberg's front and back matter using the lines that indicate the start and end of the project.\n",
    "\n",
    "Chunk by chapter, using the pattern of locating the headers in the data frame, assigning them numbers, forward-filling those numbers, and then grouping by number (and cleaning up).\n",
    "\n",
    "Split resulting data frame into paragraphs using the regex provided.\n",
    "\n",
    "Split resulting data frame into sentences using the regex provided.\n",
    "\n",
    "Split resulting data frame into tokens using the regex provided.\n",
    "\n",
    "Be sure to include the OHCO of Chapters, Paragraphs, and Sentences in your data frame's index.\n",
    "\n",
    "Once you have done this, combine both Persuasion and Sense and Sensibility into a single data frame with an appropriately modified OHCO list. In other words, make sure your index includes a new index level for the book. Use the attached CSV (austen-persuasion.csv Download austen-persuasion.csv) to get the Persuasion data and then import it into your notebook as a data frame.\n",
    "\n",
    "From the combined data frame, extract a vocabulary, i.e. a data frame with term string as index, along with term frequency and term length as features.\n",
    "\n",
    "-----\n",
    "\n",
    "After you have done all this, answer the following questions by extracting features from the corpus.\n",
    "\n",
    "1. How many raw tokens are in the combined data frame?\n",
    "\n",
    "2. How many distinct terms are there in the combined data frame (i.e. how big is the vocabulary)?\n",
    "\n",
    "3. How many more terms does the vocabulary of Sense and Sensibility have than that of Persuasion?\n",
    "\n",
    "4. What is the average number of tokens, rounded to an integer, per chapter in the corpus?\n",
    "\n",
    "5. What is the average number of tokens, rounded to an integer, per paragraph in the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = f\"{data_home}/pg161.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a notebook  to convert the raw text into a data frame of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sense and Sensibility, by Jane Austen\n"
     ]
    }
   ],
   "source": [
    "OHCO = ['chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "\n",
    "LINES = pd.DataFrame(open(text_file, 'r', encoding='utf-8-sig').readlines(), columns=['line_str'])\n",
    "LINES.index.name = 'line_num'\n",
    "LINES.line_str = LINES.line_str.str.replace(r'\\n+', ' ', regex=True).str.strip()\n",
    "\n",
    "title = LINES.loc[0].line_str.replace('The Project Gutenberg EBook of ', '')\n",
    "print(title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip Cruft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 12666\n"
     ]
    }
   ],
   "source": [
    "clip_pats = [\n",
    "    r\"\\*\\*\\*\\s*START OF (?:THE|THIS) PROJECT\",\n",
    "    r\"\\*\\*\\*\\s*END OF (?:THE|THIS) PROJECT\"\n",
    "]\n",
    "\n",
    "pat_a = LINES.line_str.str.match(clip_pats[0])\n",
    "pat_b = LINES.line_str.str.match(clip_pats[1])\n",
    "\n",
    "line_a = LINES.loc[pat_a].index[0] + 1\n",
    "line_b = LINES.loc[pat_b].index[0] - 1\n",
    "print(line_a, line_b)\n",
    "\n",
    "LINES = LINES.loc[line_a : line_b]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chapter headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_pat = r\"^\\s*(?:chapter|letter)\\s+\\d+\"\n",
    "\n",
    "chap_lines = LINES.line_str.str.match(chap_pat, case=False) # Returns a truth vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES.loc[chap_lines, 'chap_num'] = [i+1 for i in range(LINES.loc[chap_lines].shape[0])]\n",
    "#LINES.loc[chap_lines]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES.chap_num = LINES.chap_num.ffill()\n",
    "\n",
    "LINES = LINES.dropna(subset=['chap_num']) # Remove everything before Chapter 1\n",
    "# LINES = LINES.loc[~LINES.chap_num.isna()] # Remove everything before Chapter 1 (alternate method)\n",
    "LINES = LINES.loc[~chap_lines] # Remove chapter heading lines; their work is done\n",
    "LINES.chap_num = LINES.chap_num.astype('int') # Convert chap_num from float to int"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO[:1]\n",
    "['chap_num']\n",
    "# Make big string for each chapter\n",
    "CHAPS = LINES.groupby(OHCO[:1])\\\n",
    "    .line_str.apply(lambda x: '\\n'.join(x))\\\n",
    "    .to_frame('chap_str')\n",
    "\n",
    "CHAPS['chap_str'] = CHAPS.chap_str.str.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_pat = r'\\n\\n+'\n",
    "# CHAPS['chap_str'].str.split(para_pat, expand=True).head()\n",
    "PARAS = CHAPS['chap_str'].str.split(para_pat, expand=True).stack()\\\n",
    "    .to_frame('para_str').sort_index()\n",
    "PARAS.index.names = OHCO[:2]\n",
    "#PARAS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAS['para_str'] = PARAS['para_str'].str.replace(r'\\n', ' ', regex=True)\n",
    "PARAS['para_str'] = PARAS['para_str'].str.strip()\n",
    "PARAS = PARAS[~PARAS['para_str'].str.match(r'^\\s*$')] # Remove empty paragraphs\n",
    "#PARAS.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>The family of Dashwood had long been settled i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Their estate was large, and their residence wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The late owner of this estate was a single man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But her death, which happened ten years before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for to supply her loss, he invited and receive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     sent_str\n",
       "chap_num para_num sent_num                                                   \n",
       "1        0        0         The family of Dashwood had long been settled i...\n",
       "                  1         Their estate was large, and their residence wa...\n",
       "                  2         The late owner of this estate was a single man...\n",
       "                  3         But her death, which happened ten years before...\n",
       "                  4         for to supply her loss, he invited and receive..."
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent_pat = r'[.?!;:\"]+'\n",
    "sent_pat = r'[.?!;:]+'\n",
    "SENTS = PARAS['para_str'].str.split(sent_pat, expand=True).stack()\\\n",
    "    .to_frame('sent_str')\n",
    "SENTS.index.names = OHCO[:3]\n",
    "SENTS = SENTS[~SENTS['sent_str'].str.match(r'^\\s*$')] # Remove empty paragraphs\n",
    "SENTS.sent_str = SENTS.sent_str.str.strip() # CRUCIAL TO REMOVE BLANK TOKENS\n",
    "SENTS.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dashwood</td>\n",
       "      <td>dashwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>had</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">50</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">22</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sensibility</td>\n",
       "      <td>sensibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jane</td>\n",
       "      <td>jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Austen</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122882 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        token_str     term_str\n",
       "chap_num para_num sent_num token_num                          \n",
       "1        0        0        0                  The          the\n",
       "                           1               family       family\n",
       "                           2                   of           of\n",
       "                           3             Dashwood     dashwood\n",
       "                           4                  had          had\n",
       "...                                           ...          ...\n",
       "50       22       0        8                  and          and\n",
       "                           9          Sensibility  sensibility\n",
       "                           10                  by           by\n",
       "                           11                Jane         jane\n",
       "                           12              Austen       austen\n",
       "\n",
       "[122882 rows x 2 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pat = r\"[\\s',-]+\"\n",
    "TOKENS = SENTS['sent_str'].str.split(token_pat, expand=True).stack()\\\n",
    "    .to_frame('token_str')\n",
    "TOKENS.index.names = OHCO[:4]\n",
    "\n",
    "TOKENS['term_str'] = TOKENS.token_str.replace(r'[\\W_]+', '', regex=True).str.lower()\n",
    "TOKENS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download and combine Persuasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasion_csv = f\"{data_home}/austen-persuasion.csv\"\n",
    "persuasion_df = pd.read_csv(persuasion_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Sir</td>\n",
       "      <td>sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walter</td>\n",
       "      <td>walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elliot</td>\n",
       "      <td>elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kellynch</td>\n",
       "      <td>kellynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">13</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Persuasion</td>\n",
       "      <td>persuasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jane</td>\n",
       "      <td>jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Austen</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85014 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       token_str    term_str\n",
       "chap_num para_num sent_num token_num                        \n",
       "1        0        0        0                 Sir         sir\n",
       "                           1              Walter      walter\n",
       "                           2              Elliot      elliot\n",
       "                           3                  of          of\n",
       "                           4            Kellynch    kellynch\n",
       "...                                          ...         ...\n",
       "24       13       0        6                  of          of\n",
       "                           7          Persuasion  persuasion\n",
       "                           8                  by          by\n",
       "                           9                Jane        jane\n",
       "                           10             Austen      austen\n",
       "\n",
       "[85014 rows x 2 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasion_gb = persuasion_df.groupby(['chap_num', 'para_num', 'sent_num', 'token_num']).sum()\n",
    "persuasion_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Persuasion</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Sir</td>\n",
       "      <td>sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walter</td>\n",
       "      <td>walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elliot</td>\n",
       "      <td>elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kellynch</td>\n",
       "      <td>kellynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Sense and Sensibility</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">50</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">22</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sensibility</td>\n",
       "      <td>sensibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jane</td>\n",
       "      <td>jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Austen</td>\n",
       "      <td>austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207896 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              token_str  \\\n",
       "book                  chap_num para_num sent_num token_num                \n",
       "Persuasion            1        0        0        0                  Sir   \n",
       "                                                 1               Walter   \n",
       "                                                 2               Elliot   \n",
       "                                                 3                   of   \n",
       "                                                 4             Kellynch   \n",
       "...                                                                 ...   \n",
       "Sense and Sensibility 50       22       0        8                  and   \n",
       "                                                 9          Sensibility   \n",
       "                                                 10                  by   \n",
       "                                                 11                Jane   \n",
       "                                                 12              Austen   \n",
       "\n",
       "                                                               term_str  \n",
       "book                  chap_num para_num sent_num token_num               \n",
       "Persuasion            1        0        0        0                  sir  \n",
       "                                                 1               walter  \n",
       "                                                 2               elliot  \n",
       "                                                 3                   of  \n",
       "                                                 4             kellynch  \n",
       "...                                                                 ...  \n",
       "Sense and Sensibility 50       22       0        8                  and  \n",
       "                                                 9          sensibility  \n",
       "                                                 10                  by  \n",
       "                                                 11                jane  \n",
       "                                                 12              austen  \n",
       "\n",
       "[207896 rows x 2 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasion_gb['book'] = 'Persuasion'\n",
    "TOKENS['book'] = 'Sense and Sensibility'\n",
    "\n",
    "combined = pd.concat([persuasion_gb, TOKENS])\n",
    "\n",
    "combined_gb = combined.reset_index().groupby(['book', 'chap_num', 'para_num', 'sent_num', 'token_num'])[['token_str', 'term_str']].sum()\n",
    "combined_gb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have done all this, answer the following questions by extracting features from the corpus.\n",
    "\n",
    "**1. How many raw tokens are in the combined data frame?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207896"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_gb.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **207896 raw tokens** in the combined dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many distinct terms are there in the combined data frame (i.e. how big is the vocabulary)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8240"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['term_str'].value_counts().shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **8240 distinct terms** in the combined dataframe (ignoring case)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many more terms does the vocabulary of Sense and Sensibility have than that of Persuasion?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_gb.query(\"book == 'Sense and Sensibility'\")['term_str'].value_counts().shape[0] - combined_gb.query(\"book == 'Persuasion'\")['term_str'].value_counts().shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **520 more terms** in the vocab of Sense and Sensibility than Persuasion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What is the average number of tokens, rounded to an integer, per chapter in the corpus?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2809.0"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_gb.reset_index().groupby(['book', 'chap_num'])['token_num'].count().mean().round(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of tokens per chapter in the corpus is **2809**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. What is the average number of tokens, rounded to an integer, per paragraph in the corpus?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.0"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_gb.reset_index().groupby(['book', 'chap_num', 'para_num'])['token_num'].count().mean().round(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of tokens per paragraph in the corpus is **74**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
